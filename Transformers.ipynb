{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ff8217-df95-4735-82c4-bfd3b5b9ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from keras.layers import Dense,Dropout,LayerNormalization,Embedding,TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d6dc9b4-cdb2-4ca3-99f8-b40df8855b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(keras.layers.Layer):\n",
    "    def __init__(self,d_model,d_head):\n",
    "        super(MHA,self).__init__()\n",
    "        self.d_model=d_model\n",
    "        self.d_head=d_head\n",
    "        self.num_heads=int(self.d_model/self.d_head)\n",
    "        assert d_model==self.num_heads*self.d_head\n",
    "        self.q=Dense(self.d_model)\n",
    "        self.k=Dense(self.d_model)\n",
    "        self.v=Dense(self.d_model)\n",
    "        self.h=Dense(self.d_model)\n",
    "    def scaled_dot_product(self,q,k,v,mask=None):\n",
    "        a_score=tf.matmul(q,k,transpose_b=True)/np.sqrt(self.d_head)\n",
    "        if mask is not None:\n",
    "            a_score=tf.where(mask==0,-np.inf,a_score)\n",
    "        a_weights=tf.nn.softmax(a_score)\n",
    "        a_values=tf.matmul(a_weights,v)\n",
    "        return a_values,a_weights\n",
    "    def split_heads(self,x):\n",
    "        x_reshaped=tf.reshape(x,[x.shape[0],-1,self.num_heads,self.d_head])\n",
    "        x_trans=tf.transpose(x_reshaped,[0,2,1,3])\n",
    "        return x_trans\n",
    "    def merge_heads(self,x):\n",
    "        x_trans=tf.transpose(x,[0,2,1,3])\n",
    "        x_merge=tf.reshape(x_trans,[x.shape[0],-1,self.d_model])\n",
    "        return x_merge\n",
    "    def call(self,input1,input2,input3,mask=None):\n",
    "        q=self.q(input1)\n",
    "        k=self.k(input2)\n",
    "        v=self.v(input3)\n",
    "        qs,ks,vs=self.split_heads(q),self.split_heads(k),self.split_heads(v)\n",
    "        att_values,att_weights=self.scaled_dot_product(qs,ks,vs,mask)\n",
    "        merge_att_values=self.merge_heads(att_values)\n",
    "        return self.h(merge_att_values),att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4d985cb2-4a35-4b2b-b9f2-2d547edc34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.layers.Layer):\n",
    "    def __init__(self,d_model,d_head,seq_len,vocab_size,n_encoders,d_rate=0.1):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.d_model=d_model\n",
    "        self.seq_len=seq_len\n",
    "        self.n_encoders=n_encoders\n",
    "        self.att=MHA(d_model,d_head)\n",
    "        self.drop=Dropout(d_rate)\n",
    "        self.norm=LayerNormalization()\n",
    "        self.token_emd=Embedding(vocab_size,d_model)\n",
    "        self.pos_emd=Embedding(seq_len,d_model)\n",
    "    def feed_forward(self,emd_inputs):\n",
    "        feed=keras.Sequential([Dense(2*d_model,activation='relu'),Dense(d_model)])\n",
    "        return feed(emd_inputs)\n",
    "    def pos_indices(self,batch_size):\n",
    "        pos=np.arange(self.seq_len)\n",
    "        pos_batch=np.resize(pos,batch_size*self.seq_len)\n",
    "        pos_reshape=np.reshape(pos_batch,(batch_size,self.seq_len))\n",
    "        return pos_reshape\n",
    "    def encoder_output(self,inputs,training=True,mask=None):\n",
    "        a_val,a_wei=self.att(inputs,inputs,inputs,mask=mask)\n",
    "        res_val=self.drop(a_val,training=training)\n",
    "        norm_val=self.norm(res_val+inputs)\n",
    "        feed_val=self.feed_forward(norm_val)\n",
    "        res_val=self.drop(feed_val,training=training)\n",
    "        norm_val=self.norm(norm_val+res_val)\n",
    "        return norm_val,a_wei\n",
    "    def call(self,inputs,training=True):\n",
    "        mask=tf.cast(tf.math.not_equal(inputs,0),tf.float32)\n",
    "        mask=mask[:,tf.newaxis,tf.newaxis,:]\n",
    "        tok_emd=self.token_emd(inputs)\n",
    "        batch_size=inputs.shape[0]\n",
    "        pos_ind=self.pos_indices(batch_size)\n",
    "        pos_emd=self.pos_emd(pos_ind)\n",
    "        inp_emd=self.drop(tok_emd+pos_emd,training=training)\n",
    "        for i in range(self.n_encoders):\n",
    "            inp_emb,weights=self.encoder_output(inp_emd,training=training,mask=mask)\n",
    "        return inp_emb,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bd01f519-3586-490f-9f56-dc436bb8e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_head, seq_len, vocab_size, n_decoders, d_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.n_decoders = n_decoders\n",
    "        self.att1 = MHA(d_model, d_head)\n",
    "        self.att2 = MHA(d_model, d_head)\n",
    "        self.drop = Dropout(d_rate)\n",
    "        self.norm = LayerNormalization()\n",
    "        self.token_emd = Embedding(vocab_size, d_model)\n",
    "        self.pos_emd = Embedding(seq_len, d_model)\n",
    "\n",
    "    def feed_forward(self, emd_inputs):\n",
    "        feed = keras.Sequential([Dense(2 * self.d_model, activation='relu'), Dense(self.d_model)])\n",
    "        return feed(emd_inputs)\n",
    "\n",
    "    def pos_indices(self, batch_size):\n",
    "        pos = np.arange(self.seq_len)\n",
    "        pos_batch = np.resize(pos, batch_size * self.seq_len)\n",
    "        pos_reshape = np.reshape(pos_batch, (batch_size, self.seq_len))\n",
    "        return pos_reshape\n",
    "\n",
    "    def decoder_output(self, encoder_output, target, training=True, mask1=None, mask2=None):\n",
    "        a_val, a_wei = self.att1(target, target, target, mask=mask1)\n",
    "        res_val = self.drop(a_val, training=training)\n",
    "        norm_val = self.norm(res_val + target)\n",
    "        a_val, a_wei = self.att2(norm_val, encoder_output, encoder_output, mask=mask2)\n",
    "        res_val = self.drop(a_val, training=training)\n",
    "        norm_val = self.norm(norm_val + res_val)\n",
    "        feed_val = self.feed_forward(norm_val)\n",
    "        res_val = self.drop(feed_val, training=training)\n",
    "        norm_val = self.norm(norm_val + res_val)\n",
    "        return norm_val, a_wei\n",
    "\n",
    "    def call(self, enc_inp, target, training=True):\n",
    "        mask1 = tf.cast(tf.math.not_equal(target, 0), tf.float32)\n",
    "        mask2 = mask1[:, tf.newaxis, tf.newaxis, :]\n",
    "        l_tri = tf.linalg.band_part(tf.ones((self.seq_len, self.seq_len)), -1, 0)\n",
    "        mask1 = tf.minimum(mask2, l_tri)\n",
    "        tok_emd = self.token_emd(target)\n",
    "        batch_size = target.shape[0]\n",
    "        pos_ind = self.pos_indices(batch_size)\n",
    "        pos_emd = self.pos_emd(pos_ind)\n",
    "        inp_emd = self.drop(tok_emd + pos_emd, training=training)\n",
    "        for i in range(self.n_decoders):\n",
    "            inp_emb, weights = self.decoder_output(enc_inp, inp_emd, training=training, mask1=mask1, mask2=mask2)\n",
    "        return inp_emb, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5888dba2-5da2-4968-af94-cff90d3d1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(keras.models.Model):\n",
    "    def __init__(self,num_blocks,d_model,d_head,seq_len_inp,seq_len_tar,vocab_size_inp,vocab_size_tar,dropout_rate=0.1):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.encoder=Encoder(d_model,d_head,seq_len_inp,vocab_size_inp,num_blocks,d_rate=dropout_rate)\n",
    "        self.decoder=Decoder(d_model,d_head,seq_len_tar,vocab_size_tar,num_blocks,d_rate=dropout_rate)\n",
    "        self.classifier=Dense(vocab_size_tar)\n",
    "    def call(self,inps,training=True):\n",
    "        (inp_seqs,tar_seqs)=inps\n",
    "        inp_att_val,inp_att_weights=self.encoder(inp_seqs,training=training)\n",
    "        tar_att_val,tar_att_weights=self.decoder(inp_att_val,tar_seqs,training=training)\n",
    "        out=self.classifier(tar_att_val)\n",
    "        return out,inp_att_weights,tar_att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecbf0d2-0412-4294-ba6b-fc5eba402a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=load_dataset('tatoeba',lang1='en',lang2='te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807ea5c3-b8aa-45ff-961b-8dcf4712820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"I don't speak Japanese.\",\n",
       "  'What will you have?',\n",
       "  'Tell me about your daily life.'],\n",
       " ['నేను జపనీస్ మాట్లాడను',\n",
       "  'నువ్వు ఏమి తీసుకుంటావ్?',\n",
       "  'నీ రోజువారీ జీవితం గురించి చెప్పు'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds=ds['train'][:]\n",
    "source=[]\n",
    "tar=[]\n",
    "for t in train_ds['translation']:\n",
    "    source.append(t['en'])\n",
    "    tar.append(t['te'])\n",
    "source[:3],tar[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf8dbfd-0976-4ddb-8405-8e6d1f2e1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tar=['<sos> '+t+' <eos>'for t in tar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483b68a3-a867-4f32-b8b0-e9ffa25627d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ESGIND\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ESGIND\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_en=TextVectorization()\n",
    "vec_tel=TextVectorization()\n",
    "vec_tel.adapt(pre_tar)\n",
    "vec_en.adapt(source)\n",
    "source_inp=vec_en(source)\n",
    "tar_inp=vec_tel(pre_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6d310c-1323-4dba-920c-03434db30eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n",
      "634\n"
     ]
    }
   ],
   "source": [
    "s_vocab=vec_en.vocabulary_size()\n",
    "t_vocab=vec_tel.vocabulary_size()\n",
    "print(s_vocab)\n",
    "print(t_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85cfc162-3ca8-438f-ae69-81d2f7d5efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402\n",
      "1086\n"
     ]
    }
   ],
   "source": [
    "print(len(' '.join(source).split(' ')))\n",
    "print(len(' '.join(tar).split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a759c19-0cc8-4010-9261-298be59d3e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f469f79c-9c8a-4578-8e0f-c98db6ed1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=tf.zeros((tar_inp.shape[0],4),dtype=tf.int64)\n",
    "tar_inps=tf.concat([tar_inp,z],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "289a5ccd-06c7-4286-9218-5cd4168ba9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tf.data.Dataset.from_tensor_slices((source_inp,tar_inps)).shuffle(len(source)).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35e0a06c-16fb-44d5-a101-fb4c1aa37247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre=data.map(lambda c,t:((c,t[:,:-1]),t[:,1:]),tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f7c05b2-3b9b-47bc-bf5f-b565d000abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  6 100   2  78 278   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 76   7  20   0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 17), dtype=int64) tf.Tensor(\n",
      "[[  2  12 306 201   3   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2  32 560   3   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 17), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 12 306 201   3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 32 560   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(2, 17), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for c,t in data_pre.take(1):\n",
    "    print(c[0][:2],c[1][:2])\n",
    "    print(t[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a015a5dc-74c7-4f4b-a73a-f8314950b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks,d_model,d_head,seq_len_inp,seq_len_out,vocab_size_inp,vocab_size_tar=4,128,32,17,17,s_vocab,t_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d588f09b-61fe-4444-b445-eebe5f641970",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf=Transformer(num_blocks,d_model,d_head,seq_len_inp,seq_len_out,vocab_size_inp,vocab_size_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aa29fdf9-0d76-4203-bbc3-9541656183c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 17, 634)\n",
      "(8, 4, 17, 17)\n",
      "(8, 4, 17, 17)\n"
     ]
    }
   ],
   "source": [
    "o,w1,w2=trf(c)\n",
    "print(o.shape)\n",
    "print(w1.shape)\n",
    "print(w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "696839f4-d3fb-4c3f-92f3-cf6acfa4b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf.compile('adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8a4bd893-48a9-4426-8b75-41bec3582b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    logi,w1,w2=trf(c)\n",
    "    l=loss(t,o)  \n",
    "tape.gradient(l,trf.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e73b34-acef-4e31-ba10-28501b3260af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
